{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Attack\n",
    "- reference\n",
    "    - [Stupid solution to Malware classification, blog](https://thierrysilbermann.wordpress.com/2015/02/08/stupid-solution-to-malware-classification/)\n",
    "    - [malware-detection-machine-learning-approach, github](https://github.com/prk54/malware-detection-machine-learning-approach/blob/master/learning.py)\n",
    "    - [malware-detection, github](https://github.com/dchad/malware-detection)\n",
    "    - [Say no to Overfitting approaches sharing (kaggle winner team), github](https://www.kaggle.com/c/malware-classification/discussion/13490)\n",
    "    - [kaggle_Microsoft_Malware (kaggle winner team), github](https://github.com/xiaozhouwang/kaggle_Microsoft_Malware)\n",
    "    - [Notes on Parameter Tuning, xgboost](https://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import features_loader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function for visulization\n",
    "def highlight_max_in_column(s):\n",
    "    style = ['', 'font-weight: 900; color: cyan']\n",
    "    return [style[v] for v in s == s.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datas and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_dict = pkl.load(open('./dataset/fid_dict.pkl', 'rb'))\n",
    "\n",
    "with open('./dataset/training-set.csv') as f:\n",
    "    train_row = [l.split(',') for l in f.read().strip().split('\\n')]\n",
    "    train_row = [[fid_dict[l[0]], int(l[1])] for l in train_row if l[0] in fid_dict]\n",
    "    train_dict = dict(train_row)\n",
    "    train_row = np.array(train_row)\n",
    "    positive_fid = set(train_row[train_row[:, 1] == 1, 0])\n",
    "    negative_fid = set(train_row[train_row[:, 1] == 0, 0])\n",
    "\n",
    "with open('./dataset/testing-set.csv') as f:\n",
    "    test_row = [l.split(',') for l in f.read().strip().split('\\n')]\n",
    "    test_row = [l for l in test_row if l[0] in fid_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = features_loader.load_X_norm()\n",
    "X_norm_train = X_norm[:len(train_row)]\n",
    "y_train = train_row[train_row[:, 0], 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_svd6.shape: (81894, 143)\n",
      "X_svd10.shape: (81894, 147)\n",
      "X_svd100.shape: (81894, 237)\n",
      "X_svd256.shape: (81894, 393)\n"
     ]
    }
   ],
   "source": [
    "X_svd6 = features_loader.load_X_svd6()\n",
    "X_svd10 = features_loader.load_X_svd10()\n",
    "X_svd100 = features_loader.load_X_svd100()\n",
    "X_svd256 = features_loader.load_X_svd256()\n",
    "\n",
    "X_svd6_train = X_svd6[:len(train_row)]\n",
    "X_svd10_train = X_svd10[:len(train_row)]\n",
    "X_svd100_train = X_svd100[:len(train_row)]\n",
    "X_svd256_train = X_svd256[:len(train_row)]\n",
    "y_train = train_row[:len(train_row), 1]\n",
    "\n",
    "assert(X_svd6.shape[0] == 81894)\n",
    "print('X_svd6.shape:', X_svd6.shape)\n",
    "print('X_svd10.shape:', X_svd10.shape)\n",
    "print('X_svd100.shape:', X_svd100.shape)\n",
    "print('X_svd256.shape:', X_svd256.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    sumsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    max_delta_step=1,\n",
    "    reg_lambda=2,\n",
    "    gamma=1,\n",
    "    random_state=277, n_jobs=4, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model using only simple features\n",
    "- 5 fold validation for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment setting & Model setting\n",
    "n_fold = 5\n",
    "exp_models = [\n",
    "    ('X_svd6', xgb, 0),\n",
    "    ('X_svd10', xgb, 1),\n",
    "    ('X_svd100', xgb, 2),\n",
    "    ('X_svd256', xgb, 3),\n",
    "]\n",
    "\n",
    "# Validation splitter\n",
    "skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "# Expereiment result recorder\n",
    "df = pd.DataFrame(\n",
    "    index=[md_name for md_name, md, xidx in exp_models],\n",
    "    columns=['fold %d' % (i+1) for i in range(n_fold)],   \n",
    ")\n",
    "\n",
    "# Running experiment\n",
    "mean_all_record = []\n",
    "for i_fold, (tr_idx, va_idx) in enumerate(skf.split(np.arange(len(y_train)), y_train)):\n",
    "    fold_name = 'fold %d' % (i_fold+1)\n",
    "    \n",
    "    fold_x_tr = [X_svd6_train[tr_idx], X_svd10_train[tr_idx], X_svd100_train[tr_idx], X_svd256_train[tr_idx]]\n",
    "    fold_x_va = [X_svd6_train[va_idx], X_svd10_train[va_idx], X_svd100_train[va_idx], X_svd256_train[va_idx]]\n",
    "    fold_y_tr = y_train[tr_idx]\n",
    "    fold_y_va = y_train[va_idx]\n",
    "    \n",
    "    fold_record = []\n",
    "    for i_md, (md_name, md, xidx) in enumerate(exp_models):\n",
    "        print(' ' * 100, end='\\r')\n",
    "        print('Processing %s with %s' % (fold_name, md_name), end='\\r', flush=True)\n",
    "        md.fit(fold_x_tr[xidx], fold_y_tr)\n",
    "        fold_y_va_ = md.predict_proba(fold_x_va[xidx])[:, 1]\n",
    "        fold_record.append(fold_y_va_)\n",
    "        df.at[md_name, fold_name] = roc_auc_score(y_true=fold_y_va, y_score=fold_y_va_)\n",
    "    fold_y_mean_ = np.mean(fold_record, axis=0)\n",
    "    fold_y_gmean_ = scipy.stats.mstats.gmean(fold_record, axis=0)\n",
    "    df.at['y_mean', fold_name] = roc_auc_score(y_true=fold_y_va, y_score=fold_y_mean_)\n",
    "    df.at['y_gmean', fold_name] = roc_auc_score(y_true=fold_y_va, y_score=fold_y_gmean_)\n",
    "\n",
    "\n",
    "df.style.apply(highlight_max_in_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_sort_score(scores):\n",
    "    to_sort = [(*s, i) for i, s in enumerate(zip(*scores))]\n",
    "    to_sort.sort()\n",
    "    \n",
    "    same_entry = len(scores[0]) - len(set([(*s, ) for s in zip(*scores)]))\n",
    "    print('Same entry before :', same_entry)\n",
    "    \n",
    "    idx = [v[-1] for v in to_sort]\n",
    "    sort_score = np.zeros(len(to_sort), dtype=np.float64)\n",
    "    sort_score[idx] = np.arange(len(to_sort)) / (len(to_sort)-1)\n",
    "    return sort_score\n",
    "\n",
    "linear_reg = LinearRegression(normalize=True, n_jobs=4)\n",
    "linear_reg.fit(X_norm_train, y_train)\n",
    "y_linear_reg_test_ = linear_reg.predict(X_norm[len(train_row):])\n",
    "\n",
    "with open('./dataset/features/feature_label_propagate_score.txt') as f:\n",
    "    lp_score = np.array([l.split() for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    lp_score = lp_score[[fid_dict[FileID] for FileID, _ in test_row]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading ensembled answers\n",
    "weight_record = {\n",
    "    'ensemble_X_embedding_cid': 0.01,\n",
    "    'ensemble_nn_embedding': 0.01,\n",
    "    'ensemble_large': 0.01,\n",
    "    'ensemble_norm': 0.05,\n",
    "    'ensemble': 1,\n",
    "    'ensemble_svd256': 1,\n",
    "    'ensemble_stacking_old': 1,\n",
    "    'ensemble_stacking': 1,\n",
    "    'ensemble_svd256_stack_fs': 10,\n",
    "}\n",
    "\n",
    "ensembler = []\n",
    "weight = []\n",
    "for path in glob.glob('./attack/ensemble_X_embedding_cid/*.txt'):\n",
    "    with open(path) as f:\n",
    "        ans = np.array([l.split(',')[1] for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    ensembler.append(ans)\n",
    "    weight.append(weight_record['ensemble_X_embedding_cid'])\n",
    "\n",
    "for path in glob.glob('./attack/ensemble_nn_embedding/*.txt'):\n",
    "    with open(path) as f:\n",
    "        ans = np.array([l.split(',')[1] for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    ensembler.append(ans)\n",
    "    weight.append(weight_record['ensemble_nn_embedding'])\n",
    "\n",
    "for path in glob.glob('./attack/ensemble_large/*.txt'):\n",
    "    with open(path) as f:\n",
    "        ans = np.array([l.split(',')[1] for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    ensembler.append(ans)\n",
    "    weight.append(weight_record['ensemble_large'])\n",
    "\n",
    "for path in glob.glob('./attack/ensemble_norm/*.txt'):\n",
    "    ensembler.append(pkl.load(open(path, 'rb')).astype(np.float64))\n",
    "    weight.append(weight_record['ensemble_norm'])\n",
    "\n",
    "for path in glob.glob('./attack/ensemble/*.txt'):\n",
    "    with open(path) as f:\n",
    "        ans = np.array([l.split(',')[1] for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    ensembler.append(ans)\n",
    "    weight.append(weight_record['ensemble'])\n",
    "\n",
    "for path in glob.glob('./attack/ensemble_svd256/*.pkl'):\n",
    "    ensembler.append(pkl.load(open(path, 'rb')).astype(np.float64))\n",
    "    weight.append(weight_record['ensemble_svd256'])\n",
    "    \n",
    "for path in glob.glob('./attack/ensemble_stacking_old/*.pkl'):\n",
    "    ensembler.append(pkl.load(open(path, 'rb')).astype(np.float64))\n",
    "    weight.append(weight_record['ensemble_stacking_old'])\n",
    "    \n",
    "for path in glob.glob('./attack/ensemble_stacking/*.pkl'):\n",
    "    ensembler.append(pkl.load(open(path, 'rb')).astype(np.float64))\n",
    "    weight.append(weight_record['ensemble_stacking'])\n",
    "    \n",
    "for path in glob.glob('./attack/ensemble_svd256_stack_fs/*.pkl'):\n",
    "    ensembler.append(pkl.load(open(path, 'rb')).astype(np.float64))\n",
    "    weight.append(weight_record['ensemble_svd256_stack_fs'])\n",
    "\n",
    "    \n",
    "ensembler = np.array(ensembler)\n",
    "weight = np.array(weight).reshape(-1, 1)\n",
    "y_test_ = (ensembler * weight).sum(axis=0) / weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same entry before : 0\n"
     ]
    }
   ],
   "source": [
    "sort_score = get_sort_score([y_test_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./attack/82.csv', 'w') as f:\n",
    "    for i in range(len(test_row)):\n",
    "        f.write('%s,%.12f\\n' % (test_row[i][0], sort_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'========================= y_test_ =========================='"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' y_test_ '.center(60, '=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    29376.000000\n",
       "mean         0.070255\n",
       "std          0.169817\n",
       "min          0.000040\n",
       "25%          0.002160\n",
       "50%          0.008094\n",
       "75%          0.040660\n",
       "max          0.999850\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_w_lp_ = np.zeros(len(test_row))\n",
    "for i in range(len(test_row)):\n",
    "    lp, base_n, _, g_n, depth, in_edge = lp_score[i]\n",
    "    y_ = y_test_[i]\n",
    "    if base_n > 100:\n",
    "        y_test_w_lp_[i] = (lp + y_) / 2\n",
    "    elif base_n > 1:\n",
    "        y_test_w_lp_[i] = (lp * base_n + y_) / (base_n + 1)\n",
    "    else:\n",
    "        y_test_w_lp_[i] = (0 + y_) / 2\n",
    "pd.Series(y_test_w_lp_).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same entry before : 0\n"
     ]
    }
   ],
   "source": [
    "sort_score = get_sort_score([y_test_w_lp_, y_linear_reg_test_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./attack/85.csv', 'w') as f:\n",
    "    for i in range(len(test_row)):\n",
    "        f.write('%s,%.12f\\n' % (test_row[i][0], sort_score[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
