{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Attack\n",
    "- reference\n",
    "    - [Stupid solution to Malware classification, blog](https://thierrysilbermann.wordpress.com/2015/02/08/stupid-solution-to-malware-classification/)\n",
    "    - [malware-detection-machine-learning-approach, github](https://github.com/prk54/malware-detection-machine-learning-approach/blob/master/learning.py)\n",
    "    - [malware-detection, github](https://github.com/dchad/malware-detection)\n",
    "    - [Say no to Overfitting approaches sharing (kaggle winner team), github](https://www.kaggle.com/c/malware-classification/discussion/13490)\n",
    "    - [kaggle_Microsoft_Malware (kaggle winner team), github](https://github.com/xiaozhouwang/kaggle_Microsoft_Malware)\n",
    "    - [Notes on Parameter Tuning, xgboost](https://xgboost.readthedocs.io/en/latest/how_to/param_tuning.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import features_loader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Helper function for visulization\n",
    "def highlight_max_in_column(s):\n",
    "    style = ['', 'font-weight: 900; color: cyan']\n",
    "    return [style[v] for v in s == s.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datas and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_dict = pkl.load(open('./dataset/fid_dict.pkl', 'rb'))\n",
    "\n",
    "with open('./dataset/training-set.csv') as f:\n",
    "    train_row = [l.split(',') for l in f.read().strip().split('\\n')]\n",
    "    train_row = [[fid_dict[l[0]], int(l[1])] for l in train_row if l[0] in fid_dict]\n",
    "    train_dict = dict(train_row)\n",
    "    train_row = np.array(train_row)\n",
    "    positive_fid = set(train_row[train_row[:, 1] == 1, 0])\n",
    "    negative_fid = set(train_row[train_row[:, 1] == 0, 0])\n",
    "\n",
    "with open('./dataset/testing-set.csv') as f:\n",
    "    test_row = [l.split(',') for l in f.read().strip().split('\\n')]\n",
    "    test_row = [l for l in test_row if l[0] in fid_dict]\n",
    "    \n",
    "with open('./dataset/features/feature_label_propagate_score.txt') as f:\n",
    "    lp_score = np.array([l.split() for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    lp_score = lp_score[[fid_dict[FileID] for FileID, _ in test_row]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_w_lp_ = np.zeros(len(test_row))\n",
    "for i in range(len(test_row)):\n",
    "    lp, base_n, _, g_n, depth, in_edge = lp_score[i]\n",
    "    y_ = y_test_[i]\n",
    "    if base_n > 100:\n",
    "        y_test_w_lp_[i] = (lp + y_) / 2\n",
    "    elif base_n > 1:\n",
    "        y_test_w_lp_[i] = (lp * base_n + y_) / (base_n + 1)\n",
    "    else:\n",
    "        y_test_w_lp_[i] = (0 + y_) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0. , 1. , 0. , 0. , 1. , 0. , 0. , 1. , 0. , 0.5, 0. , 0. ,\n",
       "       0. , 0. , 0. , 0. , 0.5, 0. , 0. , 1. , 0. , 1. , 1. , 0. , 1. ,\n",
       "       0. , 0. , 0. , 0. , 0. , 1. , 0. , 1. , 0. , 1. , 1. , 0. , 1. ,\n",
       "       0. , 0. , 1. , 0. , 1. , 0. , 0. , 0. , 1. , 0. , 1. , 0. , 0. ,\n",
       "       0. , 1. , 0. , 0. , 0. , 1. , 1. , 0. , 0. , 1. , 1. , 1. , 0. ,\n",
       "       0. , 0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. , 1. ,\n",
       "       0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. , 0. , 0. ,\n",
       "       1. , 0. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_score[(lp_score[:,1] > 1) & (lp_score[:,1] < 100), 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (81894, 200)\n"
     ]
    }
   ],
   "source": [
    "# X_stack = [pkl.load(open(path, 'rb')) for path in sorted(glob.glob('./models/stacker/*'))]\n",
    "# X_stack = np.array(X_stack).T\n",
    "# X = np.hstack([features_loader.load_X_svd256(), X_stack])\n",
    "\n",
    "X = features_loader.load_X_svd256_stack_fs()\n",
    "X_train = X[train_row[:, 0]]\n",
    "y_train = train_row[:, 1]\n",
    "\n",
    "assert(X.shape[0] == 81894)\n",
    "print('X.shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(X[:len(train_row)], train_row[:,1], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9712244492383613"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    sumsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    max_delta_step=0,\n",
    "    reg_lambda=4,\n",
    "    random_state=277, n_jobs=16)\n",
    "model.fit(x_tr, y_tr)\n",
    "roc_auc_score(y_true=y_va, y_score=model.predict_proba(x_va)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714237981935455"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    max_features=25,\n",
    "    criterion='entropy',\n",
    "    random_state=277, n_jobs=16)\n",
    "model.fit(x_tr, y_tr)\n",
    "roc_auc_score(y_true=y_va, y_score=model.predict_proba(x_va)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971699892589286"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    max_features=25,\n",
    "    criterion='entropy',\n",
    "    random_state=277, n_jobs=16)\n",
    "model.fit(x_tr, y_tr)\n",
    "roc_auc_score(y_true=y_va, y_score=model.predict_proba(x_va)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model using only simple features\n",
    "- 5 fold validation for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 5 with XGBoosting                                                                   \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col0 {\n",
       "            font-weight:  900;\n",
       "             color:  cyan;\n",
       "        }    #T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col1 {\n",
       "            font-weight:  900;\n",
       "             color:  cyan;\n",
       "        }    #T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col2 {\n",
       "            font-weight:  900;\n",
       "             color:  cyan;\n",
       "        }    #T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col3 {\n",
       "            font-weight:  900;\n",
       "             color:  cyan;\n",
       "        }    #T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col4 {\n",
       "            font-weight:  900;\n",
       "             color:  cyan;\n",
       "        }</style>  \n",
       "<table id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >fold 1</th> \n",
       "        <th class=\"col_heading level0 col1\" >fold 2</th> \n",
       "        <th class=\"col_heading level0 col2\" >fold 3</th> \n",
       "        <th class=\"col_heading level0 col3\" >fold 4</th> \n",
       "        <th class=\"col_heading level0 col4\" >fold 5</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71level0_row0\" class=\"row_heading level0 row0\" >XGBoosting</th> \n",
       "        <td id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col0\" class=\"data row0 col0\" >0.965982</td> \n",
       "        <td id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col1\" class=\"data row0 col1\" >0.968841</td> \n",
       "        <td id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col2\" class=\"data row0 col2\" >0.972215</td> \n",
       "        <td id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col3\" class=\"data row0 col3\" >0.968281</td> \n",
       "        <td id=\"T_b36072b0_2a00_11e8_a053_40167ed8ed71row0_col4\" class=\"data row0 col4\" >0.971125</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7a8541a2b0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment setting & Model setting\n",
    "n_fold = 5\n",
    "exp_models = [\n",
    "    (\n",
    "        'XGBoosting',\n",
    "        XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            sumsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            max_delta_step=1,\n",
    "            reg_lambda=2,\n",
    "            gamma=1,\n",
    "            random_state=277, n_jobs=16)\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Validation splitter\n",
    "skf = StratifiedKFold(n_splits=n_fold)\n",
    "\n",
    "# Expereiment result recorder\n",
    "df = pd.DataFrame(\n",
    "    index=[md_name for md_name, md in exp_models],\n",
    "    columns=['fold %d' % (i+1) for i in range(n_fold)],   \n",
    ")\n",
    "\n",
    "# Running experiment\n",
    "for i_fold, (tr_idx, va_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    fold_name = 'fold %d' % (i_fold+1)\n",
    "    \n",
    "    fold_x_tr = X_train[tr_idx]\n",
    "    fold_x_va = X_train[va_idx]\n",
    "    fold_y_tr = y_train[tr_idx]\n",
    "    fold_y_va = y_train[va_idx]\n",
    "    \n",
    "    for i_md, (md_name, md) in enumerate(exp_models):\n",
    "        print(' ' * 100, end='\\r')\n",
    "        print('Processing %s with %s' % (fold_name, md_name), end='\\r', flush=True)\n",
    "        md.fit(fold_x_tr, fold_y_tr)\n",
    "        fold_y_va_ = md.predict_proba(fold_x_va)[:, 1]\n",
    "        df.at[md_name, fold_name] = roc_auc_score(y_true=fold_y_va, y_score=fold_y_va_)\n",
    "\n",
    "df.style.apply(highlight_max_in_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline attack with label propagate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=1, learning_rate=0.1, max_delta_step=1,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=5000,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       random_state=277, reg_alpha=0, reg_lambda=2, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, sumsample=0.7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "        n_estimators=5000,\n",
    "        max_depth=10,\n",
    "        sumsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        max_delta_step=1,\n",
    "        reg_lambda=2,\n",
    "        gamma=1,\n",
    "        random_state=277, n_jobs=4, silent=True\n",
    "    )\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5647d37fd708>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfid_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFileID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mFileID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_row\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset/features/feature_label_propagate_score.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlp_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_test = X[[fid_dict[FileID] for FileID, _ in test_row]]\n",
    "y_test_ = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "with open('./dataset/features/feature_label_propagate_score.txt') as f:\n",
    "    lp_score = np.array([l.split() for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    lp_score = lp_score[[fid_dict[FileID] for FileID, _ in test_row]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_w_lp_ = np.zeros(len(test_row))\n",
    "for i in range(len(test_row)):\n",
    "    lp, base_n, _, g_n, depth, in_edge = lp_score[i]\n",
    "    y_ = y_test_[i]\n",
    "    if base_n > 100:\n",
    "        y_test_w_lp_[i] = (lp + y_) / 2\n",
    "    elif base_n > 1:\n",
    "        y_test_w_lp_[i] = (lp * base_n + y_) / (base_n + 1)\n",
    "    else:\n",
    "        y_test_w_lp_[i] = (0 + y_) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./attack/57.csv', 'w') as f:\n",
    "    for i in range(len(test_row)):\n",
    "        f.write('%s,%.12f\\n' % (test_row[i][0], y_test_w_lp_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=277, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overfit = XGBClassifier(n_estimators=1000, random_state=277)\n",
    "overfit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_y_ = overfit.predict_proba(X_test)[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
