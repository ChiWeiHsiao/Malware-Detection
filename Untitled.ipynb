{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import features_loader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function for visulization\n",
    "def highlight_max_in_column(s):\n",
    "    style = ['', 'font-weight: 900; color: cyan']\n",
    "    return [style[v] for v in s == s.max()]\n",
    "\n",
    "fid_dict = pkl.load(open('./dataset/fid_dict.pkl', 'rb'))\n",
    "\n",
    "with open('./dataset/training-set.csv') as f:\n",
    "    train_row = [l.split(',') for l in f.read().strip().split('\\n')]\n",
    "    train_row = [[fid_dict[l[0]], int(l[1])] for l in train_row if l[0] in fid_dict]\n",
    "    train_dict = dict(train_row)\n",
    "    train_row = np.array(train_row)\n",
    "    positive_fid = set(train_row[train_row[:, 1] == 1, 0])\n",
    "    negative_fid = set(train_row[train_row[:, 1] == 0, 0])\n",
    "\n",
    "with open('./dataset/testing-set.csv') as f:\n",
    "    test_row = [l.split(',') for l in f.read().strip().split('\\n')]\n",
    "    test_row = [l for l in test_row if l[0] in fid_dict]\n",
    "\n",
    "with open('./dataset/features/feature_label_propagate_score.txt') as f:\n",
    "    lp_score = np.array([l.split() for l in f.read().strip().split('\\n')], dtype=np.float64)\n",
    "    lp_score = lp_score[[fid_dict[FileID] for FileID, _ in test_row]]\n",
    "    \n",
    "def get_sort_score(scores):\n",
    "    to_sort = [(*s, i) for i, s in enumerate(zip(*scores))]\n",
    "    to_sort.sort()\n",
    "    \n",
    "    same_entry = len(scores[0]) - len(set([(*s, ) for s in zip(*scores)]))\n",
    "    print('Same entry before :', same_entry)\n",
    "    \n",
    "    idx = [v[-1] for v in to_sort]\n",
    "    sort_score = np.zeros(len(to_sort), dtype=np.float64)\n",
    "    sort_score[idx] = np.arange(len(to_sort)) / (len(to_sort)-1)\n",
    "    return sort_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_svd256.shape: (81894, 393)\n"
     ]
    }
   ],
   "source": [
    "X_svd256 = features_loader.load_X_svd256()\n",
    "X_svd256_train = X_svd256[:len(train_row)]\n",
    "y_train = train_row[:len(train_row), 1]\n",
    "print('X_svd256.shape:', X_svd256.shape)\n",
    "\n",
    "x1, x2, y1, y2 = train_test_split(\n",
    "    X_svd256_train, y_train,\n",
    "    test_size=1/3,\n",
    "    random_state=277\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "            n_estimators=50,\n",
    "            max_depth=10,\n",
    "            sumsample=0.7,\n",
    "            colsample_bytree=0.7,\n",
    "            max_delta_step=1,\n",
    "            reg_lambda=2,\n",
    "            gamma=1,\n",
    "            random_state=277, n_jobs=4, silent=True)\n",
    "xgb.fit(x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(xgb, open('./models/xgb/test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=1, learning_rate=0.1, max_delta_step=1,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=50,\n",
       "       n_jobs=4, nthread=None, objective='binary:logistic',\n",
       "       random_state=277, reg_alpha=0, reg_lambda=2, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1, sumsample=0.7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_features=45,\n",
    "            class_weight='balanced_subsample',\n",
    "            criterion='entropy',\n",
    "            oob_score=True,\n",
    "            random_state=277, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
