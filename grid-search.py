import os
import time
import glob
import pickle as pkl
import scipy
import numpy as np
import pandas as pd

import features_loader

from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV


'''
Preparing data & feature
'''
fid_dict = pkl.load(open('./dataset/fid_dict.pkl', 'rb'))

with open('./dataset/training-set.csv') as f:
    train_row = [l.split(',') for l in f.read().strip().split('\n')]
    train_row = [[fid_dict[l[0]], int(l[1])] for l in train_row if l[0] in fid_dict]
    train_dict = dict(train_row)
    train_row = np.array(train_row)
    positive_fid = set(train_row[train_row[:, 1] == 1, 0])
    negative_fid = set(train_row[train_row[:, 1] == 0, 0])

with open('./dataset/testing-set.csv') as f:
    test_row = [l.split(',') for l in f.read().strip().split('\n')]
    test_row = [l for l in test_row if l[0] in fid_dict]
    
X_stack = [pkl.load(open(path, 'rb')) for path in sorted(glob.glob('./models/stacker/*'))]
X_stack = np.array(X_stack).T

X = np.hstack([features_loader.load_X_svd256(), X_stack])
X_train = X[train_row[:, 0]]
y_train = train_row[:, 1]

assert(X.shape[0] == 81894)
print('X.shape:', X.shape)
print('!!! Make sure the features are same with Attack !!!', file=sys.stderr)

'''http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py'''
# Utility function to report best scores
def report(results, n_top=3):
    for i in range(1, n_top + 1):
        candidates = np.flatnonzero(results['rank_test_score'] == i)
        for candidate in candidates:
            print("Model with rank: {0}".format(i))
            print("Mean validation score: {0:.3f} (std: {1:.3f})".format(
                  results['mean_test_score'][candidate],
                  results['std_test_score'][candidate]))
            print("Mean training score: {0:.3f} (std: {1:.3f})".format(
                  results['mean_train_score'][candidate],
                  results['std_train_score'][candidate]))
            print("Parameters: {0}".format(results['params'][candidate]))
            print("")

'''
Start grid search hyperparameters
'''
default_param = {
    'n_estimators': 100,
    'random_state': 33277,
    'silent': True,
}
param_grid = {
    'max_depth': [5, 7, 10],
    'subsample': [0.7],
#     'colsample_bytree': [0.7, 0.5, 0.3],
    'max_delta_step': [0, 1, 2],
    'reg_lambda': [1],
    'gamma': [0],
}

clf = XGBClassifier(**default_param)
model = GridSearchCV(
    estimator=clf,
    param_grid=param_grid,
    scoring='roc_auc',
    n_jobs=16,
    verbose=100,
)
model.fit(X_train, y_train, eval_metric='auc')
report(model.cv_results_, n_top=18)
